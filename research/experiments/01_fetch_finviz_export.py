# Path: research/experiments/01_fetch_finviz_export.py
from __future__ import annotations

import hashlib
import json
import os
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List

import pandas as pd
import requests
from dotenv import load_dotenv


# =============================================================================
# CONFIG (zero-arg runnable)
# =============================================================================
ROOT = Path(__file__).resolve().parents[2]  # ALGO-STOCKS/
RAW_DIR = ROOT / "data" / "raw" / "finviz"
META_DIR = ROOT / "data" / "metadata"
SCHEMA_REGISTRY_PATH = META_DIR / "schema_registry.json"

# Defaults (can be overridden via .env)
DEFAULT_TAG = "v111_all"
DEFAULT_TIMEOUT_S = 60
WRITE_PARSED_COPY = True  # default ON so you get normalized columns too

# Load .env from project root
load_dotenv(ROOT / ".env")


# =============================================================================
# Helpers
# =============================================================================
def utc_now_iso() -> str:
    return datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")


def sha1_bytes(b: bytes) -> str:
    return hashlib.sha1(b).hexdigest()


def sha1_text(s: str) -> str:
    return hashlib.sha1(s.encode("utf-8")).hexdigest()


def ensure_dirs() -> None:
    RAW_DIR.mkdir(parents=True, exist_ok=True)
    META_DIR.mkdir(parents=True, exist_ok=True)


# Path: research/experiments/01_fetch_finviz_export.py
def load_schema_registry() -> Dict:
    """
    Loads schema_registry.json safely.
    If the file is missing, empty, or invalid JSON, returns a fresh registry.
    """
    if not SCHEMA_REGISTRY_PATH.exists():
        return {"schemas": {}, "notes": "auto-generated by finviz fetcher"}

    txt = SCHEMA_REGISTRY_PATH.read_text(encoding="utf-8").strip()
    if not txt:
        return {"schemas": {}, "notes": "auto-generated by finviz fetcher"}

    try:
        obj = json.loads(txt)
        if not isinstance(obj, dict):
            return {"schemas": {}, "notes": "auto-generated by finviz fetcher"}
        obj.setdefault("schemas", {})
        obj.setdefault("notes", "auto-generated by finviz fetcher")
        return obj
    except json.JSONDecodeError:
        # Preserve a corrupted copy for debugging, then reset
        bad_path = SCHEMA_REGISTRY_PATH.with_suffix(".bad.json")
        bad_path.write_text(txt, encoding="utf-8")
        return {"schemas": {}, "notes": "auto-generated by finviz fetcher"}


def save_schema_registry(reg: Dict) -> None:
    SCHEMA_REGISTRY_PATH.write_text(json.dumps(reg, indent=2), encoding="utf-8")


def register_schema(headers: List[str], export_url: str) -> str:
    header_line = "|".join([h.strip() for h in headers])
    sig = sha1_text(header_line)

    reg = load_schema_registry()
    schemas = reg.setdefault("schemas", {})

    now = utc_now_iso()
    if sig not in schemas:
        schemas[sig] = {
            "first_seen_utc": now,
            "last_seen_utc": now,
            "source": "finviz_elite_export",
            "export_url_example": export_url,
            "headers": headers,
        }
    else:
        schemas[sig]["last_seen_utc"] = now

    save_schema_registry(reg)
    return sig


def fetch_csv_bytes(url: str, timeout_s: int) -> bytes:
    headers = {"User-Agent": "ALGO-STOCKS/0.1 (research)"}
    r = requests.get(url, headers=headers, timeout=timeout_s)
    r.raise_for_status()
    return r.content


# =============================================================================
# Main
# =============================================================================
def main() -> None:
    ensure_dirs()

    export_url = os.getenv("FINVIZ_EXPORT_URL", "").strip()
    if not export_url:
        raise RuntimeError(
            "FINVIZ_EXPORT_URL not set. Add it to .env (see .env.example)."
        )

    tag = os.getenv("FINVIZ_EXPORT_TAG", DEFAULT_TAG).strip() or DEFAULT_TAG
    timeout_s = int(os.getenv("HTTP_TIMEOUT", str(DEFAULT_TIMEOUT_S)))

    ts = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")

    print("\n=== Finviz Fetch (zero-arg runnable) ===")
    print(f"[ROOT] {ROOT}")

    def redact_auth(url: str) -> str:
        if "auth=" not in url:
            return url
        left, right = url.split("auth=", 1)
        # Keep only first 4 chars of token for sanity
        token = right.split("&", 1)[0]
        return left + "auth=" + (token[:4] + "****")

    print(f"[URL]  {redact_auth(export_url)}")

    print(f"[TAG]  {tag}  [TIMEOUT] {timeout_s}s")
    print(f"[OUT]  {RAW_DIR}")

    raw_bytes = fetch_csv_bytes(export_url, timeout_s=timeout_s)
    raw_sha1 = sha1_bytes(raw_bytes)

    raw_path = RAW_DIR / f"export_{tag}_{ts}_{raw_sha1[:10]}.csv"
    meta_path = RAW_DIR / f"export_{tag}_{ts}_{raw_sha1[:10]}.meta.json"

    raw_path.write_bytes(raw_bytes)

    # Parse CSV to capture headers + row count (no cleaning)
    df = pd.read_csv(raw_path)
    schema_sig = register_schema(list(df.columns), export_url)

    meta = {
        "downloaded_at_utc": utc_now_iso(),
        "source": "finviz_elite_export",
        "export_url": export_url,
        "raw_sha1": raw_sha1,
        "schema_signature": schema_sig,
        "rows": int(len(df)),
        "cols": int(df.shape[1]),
        "tag": tag,
    }
    meta_path.write_text(json.dumps(meta, indent=2), encoding="utf-8")

    print("\n=== Fetch Complete ===")
    print(f"[RAW]   {raw_path}")
    print(f"[META]  {meta_path}")
    print(f"[INFO]  rows={len(df)} cols={df.shape[1]} schema_sig={schema_sig}")

    # Optional: write a parsed copy with normalized column names (still no row drops)
    if WRITE_PARSED_COPY:
        df2 = df.copy()
        df2.columns = [c.strip().lower().replace(" ", "_") for c in df2.columns]
        parsed_path = RAW_DIR / f"export_{tag}_{ts}_{raw_sha1[:10]}.parsed.csv"
        df2.to_csv(parsed_path, index=False)
        print(f"[PARSED] {parsed_path}")

    print("\n[OK] Done. Raw export captured (no filtering, no dropping).")


if __name__ == "__main__":
    main()
